# 环境变量配置

<cite>
**本文档中引用的文件**
- [docker-compose.yml](file://docker-compose.yml)
- [api/main.py](file://api/main.py)
- [api/config.py](file://api/config.py)
- [api/openai_client.py](file://api/openai_client.py)
- [api/ollama_patch.py](file://api/ollama_patch.py)
- [api/google_embedder_client.py](file://api/google_embedder_client.py)
- [api/bedrock_client.py](file://api/bedrock_client.py)
- [api/azureai_client.py](file://api/azureai_client.py)
- [api/dashscope_client.py](file://api/dashscope_client.py)
- [api/logging_config.py](file://api/logging_config.py)
- [api/config/generator.json](file://api/config/generator.json)
- [api/config/embedder.json](file://api/config/embedder.json)
- [api/config/repo.json](file://api/config/repo.json)
- [api/config/lang.json](file://api/config/lang.json)
- [Dockerfile-ollama-local](file://Dockerfile-ollama-local)
</cite>

## 目录
1. [简介](#简介)
2. [核心环境变量](#核心环境变量)
3. [服务配置变量](#服务配置变量)
4. [API 密钥配置](#api-密钥配置)
5. [嵌入器配置](#嵌入器配置)
6. [容器化部署配置](#容器化部署配置)
7. [日志配置](#日志配置)
8. [配置文件系统](#配置文件系统)
9. [安全配置建议](#安全配置建议)
10. [故障排除指南](#故障排除指南)
11. [最佳实践](#最佳实践)

## 简介

deepwiki-open 是一个基于多种 AI 模型提供商的智能知识库系统，支持 OpenAI、Google AI、Ollama、AWS Bedrock、Azure OpenAI 和 Dashscope 等多个平台。本系统通过环境变量进行灵活配置，支持本地开发和生产环境的不同需求。

## 核心环境变量

### PORT（服务端口）

**作用**: 指定 API 服务器监听的端口号，默认为 8001。

**配置方式**:
```bash
# 在 .env 文件中
PORT=8001

# 或直接在命令行中设置
export PORT=8001
```

**默认值**: 8001

**注意事项**:
- 当同时运行前端和后端时，确保前端端口（3000）与后端端口不同
- 在 Docker 容器中，端口映射格式为 `-p 8001:8001`
- 生产环境中建议使用非标准端口以提高安全性

### OLLAMA_HOST（Ollama 服务地址）

**作用**: 指定 Ollama 服务的主机地址和端口，用于本地或远程 Ollama 实例连接。

**配置方式**:
```bash
# 默认本地地址
OLLAMA_HOST=http://localhost:11434

# 远程 Ollama 服务器
OLLAMA_HOST=http://ollama-server.example.com:11434

# 使用 HTTPS
OLLAMA_HOST=https://ollama.example.com:11434
```

**默认值**: http://localhost:11434

**验证检查**:
系统会自动检查 Ollama 模型可用性，确保指定的 Ollama 实例正常运行。

**节来源**
- [api/ollama_patch.py](file://api/ollama_patch.py#L21-L60)
- [Dockerfile-ollama-local](file://Dockerfile-ollama-local#L112)

## 服务配置变量

### NODE_ENV（节点环境）

**作用**: 指定应用运行环境，影响开发模式下的热重载和调试功能。

**配置方式**:
```bash
# 开发环境
NODE_ENV=development

# 生产环境  
NODE_ENV=production
```

**默认值**: production

### SERVER_BASE_URL（服务器基础 URL）

**作用**: 指定 API 服务器的基础访问地址，用于前端应用的 API 请求配置。

**配置方式**:
```bash
# 本地开发
SERVER_BASE_URL=http://localhost:8001

# 生产环境
SERVER_BASE_URL=https://api.deepwiki.example.com
```

**默认值**: http://localhost:8001

### LOG_LEVEL（日志级别）

**作用**: 设置应用程序的日志输出级别。

**可选值**:
- DEBUG: 详细的调试信息
- INFO: 一般信息记录
- WARNING: 警告信息
- ERROR: 错误信息
- CRITICAL: 严重错误

**配置方式**:
```bash
LOG_LEVEL=INFO
```

**默认值**: INFO

**节来源**
- [api/main.py](file://api/main.py#L22-L25)
- [api/logging_config.py](file://api/logging_config.py#L32)

## API 密钥配置

### OPENAI_API_KEY（OpenAI API 密钥）

**作用**: OpenAI 平台的 API 访问密钥，用于调用 GPT 系列模型和文本嵌入服务。

**获取方式**:
1. 访问 [OpenAI Platform](https://platform.openai.com/)
2. 登录您的账户
3. 导航到 "API Keys" 页面
4. 创建新的 API 密钥

**配置方式**:
```bash
OPENAI_API_KEY=sk-your-secret-key-here
```

**安全要求**:
- 不要将密钥硬编码在代码中
- 使用环境变量或加密的配置文件
- 定期轮换 API 密钥
- 限制密钥的访问权限

**依赖关系**:
- 必须设置：即使不使用 OpenAI 模型，也用于文本嵌入服务
- 支持自定义 API 端点：通过 `OPENAI_BASE_URL` 配置

**节来源**
- [api/config.py](file://api/config.py#L18)
- [api/openai_client.py](file://api/openai_client.py#L191-L195)

### GOOGLE_API_KEY（Google AI API 密钥）

**作用**: Google AI 平台的 API 访问密钥，用于调用 Gemini 系列模型和文本嵌入服务。

**获取方式**:
1. 访问 [Google AI Studio](https://aistudio.google.com/)
2. 创建新项目或选择现有项目
3. 获取 API 密钥

**配置方式**:
```bash
GOOGLE_API_KEY=your-google-api-key
```

**安全要求**:
- 与 OpenAI 密钥相同的安全标准
- 确保密钥具有适当的权限范围
- 监控 API 使用量和费用

**节来源**
- [api/config.py](file://api/config.py#L19)
- [api/google_embedder_client.py](file://api/google_embedder_client.py#L70-L76)

### OPENROUTER_API_KEY（OpenRouter API 密钥）

**作用**: OpenRouter 平台的 API 密钥，提供对多个模型提供商的统一访问接口。

**获取方式**:
1. 访问 [OpenRouter](https://openrouter.ai/)
2. 注册账户
3. 获取 API 密钥

**配置方式**:
```bash
OPENROUTER_API_KEY=sk-or-v1-your-secret-key
```

**适用场景**:
- 需要访问多个模型提供商的统一接口
- 作为主要 API 密钥的备用方案
- 实现负载均衡和故障转移

### AZURE_OPENAI_API_KEY（Azure OpenAI API 密钥）

**作用**: Azure OpenAI 服务的 API 密钥。

**配置方式**:
```bash
AZURE_OPENAI_API_KEY=your-azure-openai-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_VERSION=2024-02-15-preview
```

**认证方式**:
- 支持 API 密钥认证
- 支持 Azure Active Directory 令牌认证

**节来源**
- [api/azureai_client.py](file://api/azureai_client.py#L233-L260)

### AWS 相关配置

#### AWS_ACCESS_KEY_ID（AWS 访问密钥 ID）

#### AWS_SECRET_ACCESS_KEY（AWS 秘密访问密钥）

#### AWS_REGION（AWS 区域）

#### AWS_ROLE_ARN（AWS 角色 ARN）

**作用**: 用于 AWS Bedrock 服务的身份验证和区域配置。

**配置方式**:
```bash
AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
AWS_REGION=us-east-1
AWS_ROLE_ARN=arn:aws:iam::123456789012:role/DeepWikiRole
```

**安全要求**:
- 使用最小权限原则分配 IAM 权限
- 定期轮换访问密钥
- 使用 IAM 角色而非直接使用访问密钥

**节来源**
- [api/bedrock_client.py](file://api/bedrock_client.py#L58-L62)

### DASHSCOPE_API_KEY（阿里云 DashScope API 密钥）

**作用**: 阿里云 DashScope 平台的 API 密钥，用于访问通义千问系列模型。

**配置方式**:
```bash
DASHSCOPE_API_KEY=sk-your-dashscope-key
```

**节来源**
- [api/dashscope_client.py](file://api/dashscope_client.py#L156-L162)

## 嵌入器配置

### DEEPWIKI_EMBEDDER_TYPE（嵌入器类型）

**作用**: 指定使用的嵌入器类型，支持 openai、google 和 ollama 三种选项。

**可选值**:
- openai: 使用 OpenAI 文本嵌入模型
- google: 使用 Google 文本嵌入模型  
- ollama: 使用本地 Ollama 嵌入模型

**配置方式**:
```bash
DEEPWIKI_EMBEDDER_TYPE=openai
```

**默认值**: openai

**节来源**
- [api/config.py](file://api/config.py#L49)

## 认证配置

### DEEPWIKI_AUTH_MODE（认证模式）

**作用**: 启用或禁用 Wiki 生成的认证保护。

**配置方式**:
```bash
# 启用认证
DEEPWIKI_AUTH_MODE=true

# 或
DEEPWIKI_AUTH_MODE=1
```

**默认值**: false

### DEEPWIKI_AUTH_CODE（认证码）

**作用**: 当启用认证模式时，必须提供的认证码。

**配置方式**:
```bash
DEEPWIKI_AUTH_CODE=your-secret-auth-code
```

**安全要求**:
- 使用强随机字符串
- 定期更换认证码
- 不要在公共场合暴露

## 日志配置

### LOG_FILE_PATH（日志文件路径）

**作用**: 指定应用程序日志文件的存储路径。

**配置方式**:
```bash
LOG_FILE_PATH=/var/log/deepwiki/application.log
```

**默认值**: api/logs/application.log

### LOG_MAX_SIZE（日志文件最大大小）

**作用**: 设置单个日志文件的最大大小（以 MB 为单位）。

**配置方式**:
```bash
LOG_MAX_SIZE=50
```

**默认值**: 10

### LOG_BACKUP_COUNT（日志备份数量）

**作用**: 设置保留的日志文件备份数量。

**配置方式**:
```bash
LOG_BACKUP_COUNT=10
```

**默认值**: 5

**节来源**
- [api/logging_config.py](file://api/logging_config.py#L48-L58)

## 配置文件系统

### DEEPWIKI_CONFIG_DIR（配置目录）

**作用**: 指定自定义配置文件的存储目录。

**配置方式**:
```bash
DEEPWIKI_CONFIG_DIR=/etc/deepwiki/config
```

**默认行为**:
- 如果未设置，使用默认配置目录
- 支持相对路径和绝对路径
- 自动创建必要的目录结构

**支持的配置文件**:
- generator.json: 生成器模型配置
- embedder.json: 嵌入器配置
- repo.json: 仓库过滤规则
- lang.json: 语言支持配置

**节来源**
- [api/config.py](file://api/config.py#L52)

## 容器化部署配置

### Docker Compose 环境变量

在 `docker-compose.yml` 中定义的环境变量具有以下特点：

1. **优先级**: 环境变量 > env_file
2. **覆盖机制**: 直接指定的环境变量会覆盖 `.env` 文件中的值
3. **健康检查**: 包含端口可达性检查

**配置示例**:
```yaml
environment:
  - PORT=${PORT:-8001}
  - NODE_ENV=production
  - SERVER_BASE_URL=http://localhost:${PORT:-8001}
  - LOG_LEVEL=${LOG_LEVEL:-INFO}
  - LOG_FILE_PATH=${LOG_FILE_PATH:-api/logs/application.log}
```

### .env 文件配置

**推荐格式**:
```bash
# 基础配置
PORT=8001
NODE_ENV=production
SERVER_BASE_URL=http://localhost:8001

# API 密钥（请替换为实际密钥）
OPENAI_API_KEY=sk-your-openai-key
GOOGLE_API_KEY=your-google-key

# 可选配置
LOG_LEVEL=INFO
LOG_FILE_PATH=api/logs/application.log
DEEPWIKI_EMBEDDER_TYPE=openai
```

**节来源**
- [docker-compose.yml](file://docker-compose.yml#L9-L16)

## 安全配置建议

### 密钥管理

1. **使用环境变量**
   - 避免将密钥硬编码在代码中
   - 使用操作系统级别的环境变量管理
   - 在容器化部署中使用 secrets 管理

2. **密钥轮换**
   - 定期更新 API 密钥
   - 使用版本控制系统的密钥轮换策略
   - 监控密钥使用情况

3. **访问控制**
   - 限制密钥的访问权限
   - 使用最小权限原则
   - 定期审计密钥使用

### 网络安全

1. **HTTPS 部署**
   - 生产环境必须使用 HTTPS
   - 配置有效的 SSL/TLS 证书
   - 强制 HTTPS 重定向

2. **防火墙配置**
   - 仅开放必要的端口
   - 限制访问来源 IP 地址
   - 使用反向代理层

3. **API 限流**
   - 实施请求频率限制
   - 监控异常使用模式
   - 设置合理的配额

### 数据保护

1. **敏感数据加密**
   - 加密存储的配置文件
   - 使用安全的密钥管理系统
   - 定期清理临时文件

2. **日志安全**
   - 避日在日志中记录敏感信息
   - 实施日志轮转和归档
   - 监控日志访问权限

## 故障排除指南

### 常见配置错误

#### 1. 缺失必填环境变量

**症状**: 应用启动时出现警告或错误

**诊断命令**:
```bash
# 检查环境变量是否设置
printenv | grep -E "(OPENAI_API_KEY|GOOGLE_API_KEY)"

# 验证特定变量
echo $OPENAI_API_KEY
```

**解决方案**:
```bash
# 设置缺失的环境变量
export OPENAI_API_KEY=your-key
export GOOGLE_API_KEY=your-key

# 或添加到 .env 文件
echo "OPENAI_API_KEY=your-key" >> .env
echo "GOOGLE_API_KEY=your-key" >> .env
```

**节来源**
- [api/main.py](file://api/main.py#L47-L52)

#### 2. 端口冲突

**症状**: 无法绑定到指定端口

**诊断命令**:
```bash
# 检查端口占用
netstat -tulpn | grep :8001
lsof -i :8001
```

**解决方案**:
```bash
# 更改端口
export PORT=8002

# 或停止占用端口的进程
sudo kill -9 $(lsof -t -i:8001)
```

#### 3. Ollama 连接问题

**症状**: Ollama 模型不可用或连接超时

**诊断步骤**:
```bash
# 检查 Ollama 服务状态
curl http://localhost:11434/api/tags

# 验证网络连接
ping localhost
telnet localhost 11434
```

**解决方案**:
```bash
# 启动 Ollama 服务
ollama serve

# 或配置远程 Ollama 服务器
export OLLAMA_HOST=http://remote-server:11434
```

#### 4. API 密钥无效

**症状**: API 调用失败或返回认证错误

**诊断方法**:
```bash
# 测试 OpenAI API 密钥
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/models

# 测试 Google API 密钥
curl -H "Authorization: Bearer $GOOGLE_API_KEY" \
     https://generativelanguage.googleapis.com/v1beta/models
```

**解决方案**:
1. 验证密钥格式正确
2. 检查密钥权限设置
3. 确认账户余额充足
4. 更新过期的密钥

### 性能优化配置

#### 1. 嵌入器性能调优

**OpenAI 嵌入器**:
```bash
# 使用较小维度的模型
DEEPWIKI_EMBEDDER_TYPE=openai
# 修改 embedder.json 中的 dimensions: 256
```

**Google 嵌入器**:
```bash
# 使用轻量级模型
DEEPWIKI_EMBEDDER_TYPE=google
# 修改 embedder.json 中的 model: "text-embedding-004"
```

#### 2. 批处理优化

**配置批量大小**:
```bash
# 修改 embedder.json 中的 batch_size 参数
# OpenAI: 500
# Google: 100
# Ollama: 根据内存调整
```

#### 3. 缓存配置

**启用嵌入缓存**:
```bash
# 配置本地缓存目录
export DEEPWIKI_CACHE_DIR=/path/to/cache
```

### 监控和维护

#### 1. 健康检查

**监控端点**:
```bash
# 检查应用健康状态
curl http://localhost:8001/health

# 检查 Ollama 状态
curl http://localhost:11434/api/version
```

#### 2. 日志分析

**常见日志模式**:
```bash
# 查找错误日志
grep -i error api/logs/application.log

# 监控 API 调用
grep "API call" api/logs/application.log

# 分析响应时间
grep "response_time" api/logs/application.log
```

#### 3. 资源监控

**系统资源监控**:
```bash
# CPU 和内存使用
htop

# 磁盘空间
df -h

# 网络连接
ss -tuln | grep :8001
```

## 最佳实践

### 开发环境配置

1. **本地开发**
```bash
# .env.development
PORT=8001
NODE_ENV=development
SERVER_BASE_URL=http://localhost:8001
LOG_LEVEL=DEBUG
OPENAI_API_KEY=sk-dev-key
GOOGLE_API_KEY=dev-key
```

2. **测试环境**
```bash
# .env.test
PORT=8002
NODE_ENV=test
SERVER_BASE_URL=http://test-server:8002
LOG_LEVEL=INFO
OPENAI_API_KEY=sk-test-key
GOOGLE_API_KEY=test-key
```

### 生产环境配置

1. **安全配置**
```bash
# .env.production
PORT=8001
NODE_ENV=production
SERVER_BASE_URL=https://api.deepwiki.example.com
LOG_LEVEL=WARNING
LOG_FILE_PATH=/var/log/deepwiki/application.log
LOG_MAX_SIZE=50
LOG_BACKUP_COUNT=10
```

2. **高可用配置**
```bash
# 多实例部署
export DEEPWIKI_CLUSTER_SIZE=3
export DEEPWIKI_LOAD_BALANCER=nginx
```

### 配置模板

**完整配置模板**:
```bash
# ====================
# 基础配置
# ====================
PORT=8001
NODE_ENV=production
SERVER_BASE_URL=https://api.deepwiki.example.com

# ====================
# API 密钥配置
# ====================
OPENAI_API_KEY=sk-your-production-key
GOOGLE_API_KEY=your-google-production-key
OPENROUTER_API_KEY=sk-or-v1-your-key
AZURE_OPENAI_API_KEY=your-azure-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_VERSION=2024-02-15-preview

# ====================
# 服务配置
# ====================
OLLAMA_HOST=http://localhost:11434
DEEPWIKI_EMBEDDER_TYPE=openai
DEEPWIKI_AUTH_MODE=false

# ====================
# 日志配置
# ====================
LOG_LEVEL=INFO
LOG_FILE_PATH=/var/log/deepwiki/application.log
LOG_MAX_SIZE=50
LOG_BACKUP_COUNT=10

# ====================
# 认证配置
# ====================
DEEPWIKI_AUTH_CODE=your-secret-auth-code

# ====================
# 高级配置
# ====================
DEEPWIKI_CONFIG_DIR=/etc/deepwiki/config
```

### 部署检查清单

1. **环境准备**
   - [ ] 确认系统依赖已安装
   - [ ] 配置防火墙规则
   - [ ] 设置域名解析

2. **密钥管理**
   - [ ] API 密钥已正确配置
   - [ ] 密钥权限已设置
   - [ ] 密钥已加密存储

3. **服务配置**
   - [ ] 端口配置正确
   - [ ] 网络连接正常
   - [ ] DNS 解析工作

4. **安全设置**
   - [ ] HTTPS 已启用
   - [ ] 访问控制已配置
   - [ ] 安全审计已开启

5. **监控配置**
   - [ ] 健康检查端点可用
   - [ ] 日志记录正常
   - [ ] 性能指标已监控

通过遵循这些配置指南和最佳实践，您可以确保 deepwiki-open 系统的安全、稳定和高效运行。定期审查和更新配置，根据实际使用情况进行优化调整。